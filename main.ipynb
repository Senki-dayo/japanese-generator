{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文の数: 49523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:25<00:00,  1.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 49523/49523 [55:52<00:00,  8.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_three_words_list(sentence):  # 関数にする\n",
    "    \"\"\"文章を3単語の組にして返す\"\"\"\n",
    "    t = Tokenizer()\n",
    "    words = t.tokenize(sentence, wakati=True)\n",
    "    words = [BEGIN] + words + [END]\n",
    "    three_words_list = []\n",
    "    for i in range(len(words) - 2):\n",
    "        three_words_list.append(tuple(words[i:i+3]))\n",
    "    return three_words_list\n",
    "\n",
    "def generate_markov_dict(three_words_count):\n",
    "    \"\"\"マルコフ連鎖での文章生成用の辞書データを生成する\"\"\"\n",
    "    markov_dict = {}\n",
    "    for three_words, count in three_words_count.items():\n",
    "        two_words = three_words[:2]  # 「前半2つの単語」と「次の単語」に分割\n",
    "        next_word = three_words[2]\n",
    "        if two_words not in markov_dict: # 辞書に存在しない場合は空データを生成\n",
    "            markov_dict[two_words] = {'words': [], 'weights': []}\n",
    "        markov_dict[two_words]['words'].append(next_word)  # 次の単語と回数を追加\n",
    "        markov_dict[two_words]['weights'].append(count)\n",
    "    return markov_dict\n",
    "\n",
    "\n",
    "def get_first_words_weights(three_words_count):\n",
    "    \"\"\"最初の単語を選択するための辞書データを作成する\"\"\"\n",
    "    first_word_count = defaultdict(int)\n",
    "\n",
    "    for three_words, count in three_words_count.items():\n",
    "        if three_words[0] == BEGIN:\n",
    "            next_word = three_words[1]\n",
    "            first_word_count[next_word] += count\n",
    "\n",
    "    words = []  # 単語と重み(出現回数)を格納するリスト\n",
    "    weights = []\n",
    "    for word, count in first_word_count.items():\n",
    "        words.append(word)  # 単語と重みをリストに追加\n",
    "        weights.append(count)\n",
    "            \n",
    "    return words, weights\n",
    "\n",
    "BEGIN = '__BEGIN__'  # 文の開始マーク\n",
    "END = '__END__'  # 文の終了マーク\n",
    "\n",
    "data =open('Japanese.txt', encoding=\"utf-8_sig\") \n",
    "data1=data.read()\n",
    "data.close()\n",
    "\n",
    "sentences = data1.split('。')  # 。で文章を分割\n",
    "print('文の数:', len(sentences))\n",
    "sentences[:10]\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(50)):  # tqdm()で囲む\n",
    "    time.sleep(0.5)  # 0.5秒スリープ\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "three_words_list = []\n",
    "for sentence in tqdm(sentences):  # tqdmで進捗バーを表示する\n",
    "    three_words_list += get_three_words_list(sentence)\n",
    "three_words_count = Counter(three_words_list)\n",
    "len(three_words_count)  # 3単語の組の種類を確認\n",
    "\n",
    "markov_dict = generate_markov_dict(three_words_count)  # 文章生成用の辞書データを作成\n",
    "first_words, first_weights = get_first_words_weights(three_words_count)  # 最初の単語と出現数を取得\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def generate_text(fwords, fweights, markov_dict):\n",
    "    \"\"\"入力された辞書データを元に文章を生成する\"\"\"\n",
    "    first_word = random.choices(fwords, weights=fweights)[0]  # 最初の単語を取得\n",
    "    generate_words = [BEGIN, first_word]  # 文章生成用に単語を格納するリスト\n",
    "    while True:\n",
    "        pair = tuple(generate_words[-2:])  # 最後の2つの単語を取得\n",
    "        words = markov_dict[pair]['words']  # 次の単語と重みのリストを取得\n",
    "        weights = markov_dict[pair]['weights']\n",
    "        next_word = random.choices(words, weights=weights)[0]  # 次の単語を取得\n",
    "        if next_word == END:  # 文章が終了した場合はループを抜ける\n",
    "            break\n",
    "        generate_words.append(next_word)\n",
    "\n",
    "    return ''.join(generate_words[1:])  # 単語から文章を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "彼女は彼には何でも読みなさい\n",
      "物価が安くつく\n",
      "会社へ電話できますか\n",
      "私たちを行かせた\n",
      "私は彼を責めることは知らない\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sentence = generate_text(first_words, first_weights, markov_dict)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
